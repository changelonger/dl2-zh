{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbd22e29",
   "metadata": {},
   "source": [
    "## 1.数据操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b81ddd",
   "metadata": {},
   "source": [
    "### 1.1入门"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1f2b007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54580d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90da1178",
   "metadata": {},
   "source": [
    "可以通过张量的shape属性来访问张量（沿每个轴的⻓度）的形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a08158d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c48816",
   "metadata": {},
   "source": [
    "如果只想知道张量中元素的总数，即形状的所有元素乘积，可以检查它的⼤⼩（size）。因为这⾥在处理的是\n",
    "⼀个向量，所以它的shape与它的size相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d39e6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a48279",
   "metadata": {},
   "source": [
    "要想改变⼀个张量的形状⽽不改变元素数量和元素值，可以调⽤reshape函数。例如，可以把张量x从形状为\n",
    "（12,）的⾏向量转换为形状为（3,4）的矩阵。这个新的张量包含与转换前相同的值，但是它被看成⼀个3⾏4列\n",
    "的矩阵。要重点说明⼀下，虽然张量的形状发⽣了改变，但其元素值并没有变。注意，通过改变张量的形状，\n",
    "张量的⼤⼩不会改变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1579dc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape(3,4)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e473c0",
   "metadata": {},
   "source": [
    "可以通过-1来调⽤此⾃动计算出维度的功能\n",
    "比如⽤x.reshape(-1,4)或x.reshape(3,-1)来取代x.reshape(3,4)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f523984",
   "metadata": {},
   "source": [
    "全0的张量：torch.zeros(shape)\n",
    "全1的张量：torch.ones(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad16b50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2aaecf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2,3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddc2e8e",
   "metadata": {},
   "source": [
    "有时我们想通过从某个特定的概率分布中随机采样来得到张量中每个元素的值。例如，当我们构造数组来作\n",
    "为神经⽹络中的参数时，我们通常会随机初始化参数的值。   \n",
    "以下代码创建⼀个形状为（3,4）的张量。其中的\n",
    "每个元素都从均值为0、标准差为1的标准⾼斯分布（正态分布）中随机采样   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fe5ed41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5798,  0.8845, -0.9819,  0.5626],\n",
       "        [-2.7689,  0.9150, -1.0327, -0.7810],\n",
       "        [ 1.0061, -1.4976, -1.3318,  0.4418]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aa8476",
   "metadata": {},
   "source": [
    "我们还可以通过提供包含数值的Python列表（或嵌套列表），来为所需张量中的每个元素赋予确定值。在这\n",
    "⾥，最外层的列表对应于轴0，内层的列表对应于轴1。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "503bf482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 4, 3],\n",
       "        [1, 2, 3, 4],\n",
       "        [4, 3, 2, 1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050b3d5e",
   "metadata": {},
   "source": [
    "###  1.2 运算符"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac373dd",
   "metadata": {},
   "source": [
    "对于任意具有相同形状的张量，常⻅的标准算术运算符（+、-、*、/和**）都可以被升级为按元素运算。   \n",
    "我们可以在同⼀形状的任意两个张量上调⽤按元素操作。在下⾯的例⼦中，我们使⽤逗号来表⽰⼀个具有5个    \n",
    "元素的元组，其中每个元素都是按元素操作的结果。    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0d69707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3.,  4.,  6., 10.]),\n",
       " tensor([-1.,  0.,  2.,  6.]),\n",
       " tensor([ 2.,  4.,  8., 16.]),\n",
       " tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n",
       " tensor([ 1.,  4., 16., 64.]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0,2,4,8])\n",
    "y = torch.tensor([2,2,2,2,])\n",
    "x + y,x - y,x * y,x / y,x ** y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b286c55",
   "metadata": {},
   "source": [
    "“按元素”⽅式可以应⽤更多的计算，包括像求幂这样的⼀元运算符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39773dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f45fb5e",
   "metadata": {},
   "source": [
    "我们也可以把多个张量连结（concatenate）在⼀起，把它们端对端地叠起来形成⼀个更⼤的张量。 我们只需要提供张量列表，并给出沿哪个轴连结。下⾯的例⼦分别演⽰了当我们沿⾏（轴-0，形状的第⼀个元素）和按   \n",
    "列（轴-1，形状的第⼆个元素）连结两个矩阵时，会发⽣什么情况。我们可以看到，第⼀个输出张量的轴-0⻓   \n",
    "度（6）是两个输⼊张量轴-0⻓度的总和（3 + 3）；第⼆个输出张量的轴-1⻓度（8）是两个输⼊张量轴-1⻓度的总和（4 + 4）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66ec79b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 2.,  1.,  4.,  3.],\n",
       "         [ 1.,  2.,  3.,  4.],\n",
       "         [ 4.,  3.,  2.,  1.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
       "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f9ca31",
   "metadata": {},
   "source": [
    "按照行和列拼接"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90525d34",
   "metadata": {},
   "source": [
    "有时，我们想通过逻辑运算符构建⼆元张量。以X == Y为例：对于每个位置，如果X和Y在该位置相等，则新\n",
    "张量中相应项的值为1。这意味着逻辑语句X == Y在该位置处为真，否则该位置为0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3a39c18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X == Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a36fc2",
   "metadata": {},
   "source": [
    "对张量中的所有元素进⾏求和，会产⽣⼀个单元素张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d3d92dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(66.)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc78130",
   "metadata": {},
   "source": [
    "### 1.3 广播机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9abb65a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1b1b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
